train:
  total_episodes: 1000
  rollout_size: 128
  batch_size: 64
  epochs: 10
  learning_rate: 1e-4
  gamma: 0.99
  lam: 0.95
  clip_eps: 0.2
  save_interval: 100
  action_std_decay: 0.01
  min_action_std: 0.1

env:
  max_steps: 100   # episode length

model:
  hidden_sizes: [256, 128, 64]   # actor-critic MLP 깊이와 크기
  save_path: "/home/home/soarm_tutorial/policy/PPO/checkpoints"

robot:
  joint_limits: # rad
      lower: [-1.5708, 0.0,    0.0,     -3.1416, -1.5708, -0.1745]
      upper: [ 1.5708, 3.1416, 3.1416,  0.0,      1.5708,  0.8727]