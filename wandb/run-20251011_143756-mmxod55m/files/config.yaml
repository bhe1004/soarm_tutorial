_wandb:
    value:
        cli_version: 0.21.3
        e:
            w345ylhjz73xej2uw1l0szylz8vnmirk:
                args:
                    - --wandb
                codePath: isaac_env/env/train.py
                codePathLocal: isaac_env/env/train.py
                cpu_count: 10
                cpu_count_logical: 10
                cudaVersion: "12.8"
                disk:
                    /:
                        total: "983247642624"
                        used: "702794784768"
                email: pakbohyong0717@gmail.com
                executable: /home/home/isaacsim/_build/linux-x86_64/release/kit/python/bin/python3
                git:
                    commit: 25d1f36a9f81c6c2b2a6eb80fcd934817296d5cf
                    remote: https://github.com/bhe1004/soarm_tutorial.git
                gpu: NVIDIA GeForce RTX 5070
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Blackwell
                      cudaCores: 6144
                      memoryTotal: "12820938752"
                      name: NVIDIA GeForce RTX 5070
                      uuid: GPU-c450e067-8610-e678-c4cb-409ef308a10f
                host: home
                memory:
                    total: "33259446272"
                os: Linux-6.8.0-85-generic-x86_64-with-glibc2.35
                program: /home/home/soarm_tutorial/isaac_env/env/train.py
                python: CPython 3.11.13
                root: /home/home/soarm_tutorial
                startedAt: "2025-10-11T05:37:56.909227Z"
                writerId: w345ylhjz73xej2uw1l0szylz8vnmirk
        m: []
        python_version: 3.11.13
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 2
                - 13
                - 16
            "4": 3.11.13
            "5": 0.21.3
            "12": 0.21.3
            "13": linux-x86_64
env:
    value:
        max_steps: 500
model:
    value:
        hidden_sizes:
            - 256
            - 128
        save_path: /home/home/soarm_tutorial/policy/PPO/checkpoints
robot:
    value:
        joint_limits:
            lower:
                - -1.5708
                - 0
                - -3.1416
                - -3.1416
                - -1.5708
                - -0.1745
            upper:
                - 1.5708
                - 3.1416
                - 0
                - 0
                - 1.5708
                - 0.8727
train:
    value:
        action_std_decay: 0.01
        batch_size: 64
        clip_eps: 0.2
        entropy_bonus: 0.01
        epochs: 10
        gamma: 0.99
        lam: 0.95
        learning_rate: "1e-4"
        min_action_std: 0.1
        rollout_size: 256
        save_interval: 500
        total_episodes: 10000
